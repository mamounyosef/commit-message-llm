{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.4,
  "eval_steps": 500,
  "global_step": 6000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006,
      "grad_norm": 2.8921620845794678,
      "learning_rate": 3.866666666666667e-05,
      "loss": 3.9705,
      "step": 30
    },
    {
      "epoch": 0.012,
      "grad_norm": 2.8989145755767822,
      "learning_rate": 7.866666666666666e-05,
      "loss": 3.5575,
      "step": 60
    },
    {
      "epoch": 0.018,
      "grad_norm": 3.2968666553497314,
      "learning_rate": 0.00011866666666666669,
      "loss": 3.3113,
      "step": 90
    },
    {
      "epoch": 0.024,
      "grad_norm": 2.4024198055267334,
      "learning_rate": 0.00015866666666666668,
      "loss": 3.2512,
      "step": 120
    },
    {
      "epoch": 0.03,
      "grad_norm": 3.3584930896759033,
      "learning_rate": 0.00019866666666666668,
      "loss": 3.2421,
      "step": 150
    },
    {
      "epoch": 0.036,
      "grad_norm": 1.8384349346160889,
      "learning_rate": 0.0001999823571192959,
      "loss": 3.1518,
      "step": 180
    },
    {
      "epoch": 0.042,
      "grad_norm": 2.2642838954925537,
      "learning_rate": 0.00019992698073861064,
      "loss": 3.159,
      "step": 210
    },
    {
      "epoch": 0.048,
      "grad_norm": 2.606353759765625,
      "learning_rate": 0.00019983387078962631,
      "loss": 3.1853,
      "step": 240
    },
    {
      "epoch": 0.054,
      "grad_norm": 1.9439256191253662,
      "learning_rate": 0.00019970306243172222,
      "loss": 3.1207,
      "step": 270
    },
    {
      "epoch": 0.06,
      "grad_norm": 3.0193405151367188,
      "learning_rate": 0.0001995346050596271,
      "loss": 3.1289,
      "step": 300
    },
    {
      "epoch": 0.066,
      "grad_norm": 2.4862546920776367,
      "learning_rate": 0.00019932856228476706,
      "loss": 3.0435,
      "step": 330
    },
    {
      "epoch": 0.072,
      "grad_norm": 2.0865681171417236,
      "learning_rate": 0.00019908501191124534,
      "loss": 3.0715,
      "step": 360
    },
    {
      "epoch": 0.078,
      "grad_norm": 2.817326545715332,
      "learning_rate": 0.00019880404590646232,
      "loss": 3.1102,
      "step": 390
    },
    {
      "epoch": 0.084,
      "grad_norm": 1.9509340524673462,
      "learning_rate": 0.00019848577036638788,
      "loss": 3.0465,
      "step": 420
    },
    {
      "epoch": 0.09,
      "grad_norm": 2.8550503253936768,
      "learning_rate": 0.00019813030547549803,
      "loss": 3.1473,
      "step": 450
    },
    {
      "epoch": 0.096,
      "grad_norm": 1.9244855642318726,
      "learning_rate": 0.00019773778546139227,
      "loss": 3.0609,
      "step": 480
    },
    {
      "epoch": 0.1,
      "eval_loss": 3.0791115760803223,
      "eval_runtime": 398.5931,
      "eval_samples_per_second": 37.632,
      "eval_steps_per_second": 6.272,
      "step": 500
    },
    {
      "epoch": 0.102,
      "grad_norm": 1.6501675844192505,
      "learning_rate": 0.00019730835854410726,
      "loss": 3.0676,
      "step": 510
    },
    {
      "epoch": 0.108,
      "grad_norm": 2.2072839736938477,
      "learning_rate": 0.00019684218688014772,
      "loss": 3.0838,
      "step": 540
    },
    {
      "epoch": 0.114,
      "grad_norm": 1.9873464107513428,
      "learning_rate": 0.00019633944650125388,
      "loss": 3.0418,
      "step": 570
    },
    {
      "epoch": 0.12,
      "grad_norm": 3.21879243850708,
      "learning_rate": 0.0001958003272479301,
      "loss": 3.1029,
      "step": 600
    },
    {
      "epoch": 0.126,
      "grad_norm": 2.1942484378814697,
      "learning_rate": 0.00019522503269775899,
      "loss": 3.0015,
      "step": 630
    },
    {
      "epoch": 0.132,
      "grad_norm": 2.124021530151367,
      "learning_rate": 0.00019461378008852785,
      "loss": 3.0896,
      "step": 660
    },
    {
      "epoch": 0.138,
      "grad_norm": 1.8952687978744507,
      "learning_rate": 0.00019396680023619765,
      "loss": 3.017,
      "step": 690
    },
    {
      "epoch": 0.144,
      "grad_norm": 2.2599117755889893,
      "learning_rate": 0.000193284337447744,
      "loss": 3.0242,
      "step": 720
    },
    {
      "epoch": 0.15,
      "grad_norm": 2.488922119140625,
      "learning_rate": 0.00019256664942890413,
      "loss": 3.0515,
      "step": 750
    },
    {
      "epoch": 0.156,
      "grad_norm": 1.9495731592178345,
      "learning_rate": 0.0001918140071868642,
      "loss": 3.0304,
      "step": 780
    },
    {
      "epoch": 0.162,
      "grad_norm": 1.5355409383773804,
      "learning_rate": 0.00019102669492792405,
      "loss": 2.9801,
      "step": 810
    },
    {
      "epoch": 0.168,
      "grad_norm": 2.112929105758667,
      "learning_rate": 0.00019020500995017747,
      "loss": 3.0405,
      "step": 840
    },
    {
      "epoch": 0.174,
      "grad_norm": 1.721645712852478,
      "learning_rate": 0.00018934926253124921,
      "loss": 2.9475,
      "step": 870
    },
    {
      "epoch": 0.18,
      "grad_norm": 2.607774257659912,
      "learning_rate": 0.00018845977581113046,
      "loss": 3.0706,
      "step": 900
    },
    {
      "epoch": 0.186,
      "grad_norm": 2.029932975769043,
      "learning_rate": 0.0001875368856701576,
      "loss": 3.026,
      "step": 930
    },
    {
      "epoch": 0.192,
      "grad_norm": 1.9444793462753296,
      "learning_rate": 0.00018658094060217999,
      "loss": 2.967,
      "step": 960
    },
    {
      "epoch": 0.198,
      "grad_norm": 2.3265745639801025,
      "learning_rate": 0.00018559230158296454,
      "loss": 3.0602,
      "step": 990
    },
    {
      "epoch": 0.2,
      "eval_loss": 3.0215213298797607,
      "eval_runtime": 389.728,
      "eval_samples_per_second": 38.488,
      "eval_steps_per_second": 6.415,
      "step": 1000
    },
    {
      "epoch": 0.204,
      "grad_norm": 1.985264539718628,
      "learning_rate": 0.0001845713419338873,
      "loss": 2.991,
      "step": 1020
    },
    {
      "epoch": 0.21,
      "grad_norm": 2.467372179031372,
      "learning_rate": 0.0001835184471809631,
      "loss": 3.0303,
      "step": 1050
    },
    {
      "epoch": 0.216,
      "grad_norm": 2.01712965965271,
      "learning_rate": 0.0001824340149092662,
      "loss": 3.0045,
      "step": 1080
    },
    {
      "epoch": 0.222,
      "grad_norm": 1.6325531005859375,
      "learning_rate": 0.00018131845461279812,
      "loss": 3.0223,
      "step": 1110
    },
    {
      "epoch": 0.228,
      "grad_norm": 2.1616098880767822,
      "learning_rate": 0.0001801721875398576,
      "loss": 2.9937,
      "step": 1140
    },
    {
      "epoch": 0.234,
      "grad_norm": 1.728508472442627,
      "learning_rate": 0.00017899564653397262,
      "loss": 3.0118,
      "step": 1170
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.7592434883117676,
      "learning_rate": 0.00017778927587045373,
      "loss": 3.1557,
      "step": 1200
    },
    {
      "epoch": 0.246,
      "grad_norm": 1.764804482460022,
      "learning_rate": 0.00017655353108863068,
      "loss": 2.9652,
      "step": 1230
    },
    {
      "epoch": 0.252,
      "grad_norm": 1.9444425106048584,
      "learning_rate": 0.0001752888788198355,
      "loss": 2.9996,
      "step": 1260
    },
    {
      "epoch": 0.258,
      "grad_norm": 2.1938326358795166,
      "learning_rate": 0.00017399579661119715,
      "loss": 3.0137,
      "step": 1290
    },
    {
      "epoch": 0.264,
      "grad_norm": 1.9020808935165405,
      "learning_rate": 0.00017267477274531432,
      "loss": 2.9484,
      "step": 1320
    },
    {
      "epoch": 0.27,
      "grad_norm": 2.272019624710083,
      "learning_rate": 0.00017132630605587435,
      "loss": 3.0464,
      "step": 1350
    },
    {
      "epoch": 0.276,
      "grad_norm": 1.6711468696594238,
      "learning_rate": 0.00016995090573928797,
      "loss": 2.9652,
      "step": 1380
    },
    {
      "epoch": 0.282,
      "grad_norm": 1.795166015625,
      "learning_rate": 0.0001685490911624109,
      "loss": 3.0618,
      "step": 1410
    },
    {
      "epoch": 0.288,
      "grad_norm": 2.513688087463379,
      "learning_rate": 0.00016712139166642488,
      "loss": 3.0041,
      "step": 1440
    },
    {
      "epoch": 0.294,
      "grad_norm": 1.841731071472168,
      "learning_rate": 0.00016566834636695264,
      "loss": 2.9565,
      "step": 1470
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.4856131076812744,
      "learning_rate": 0.00016419050395048148,
      "loss": 2.9925,
      "step": 1500
    },
    {
      "epoch": 0.3,
      "eval_loss": 2.9887754917144775,
      "eval_runtime": 405.1299,
      "eval_samples_per_second": 37.025,
      "eval_steps_per_second": 6.171,
      "step": 1500
    },
    {
      "epoch": 0.306,
      "grad_norm": 2.0066444873809814,
      "learning_rate": 0.00016268842246717306,
      "loss": 2.9662,
      "step": 1530
    },
    {
      "epoch": 0.312,
      "grad_norm": 1.5821243524551392,
      "learning_rate": 0.00016116266912013732,
      "loss": 2.9989,
      "step": 1560
    },
    {
      "epoch": 0.318,
      "grad_norm": 2.4008402824401855,
      "learning_rate": 0.0001596138200512501,
      "loss": 3.0094,
      "step": 1590
    },
    {
      "epoch": 0.324,
      "grad_norm": 1.8263236284255981,
      "learning_rate": 0.00015804246012359534,
      "loss": 2.9752,
      "step": 1620
    },
    {
      "epoch": 0.33,
      "grad_norm": 2.26908278465271,
      "learning_rate": 0.00015644918270061418,
      "loss": 2.9918,
      "step": 1650
    },
    {
      "epoch": 0.336,
      "grad_norm": 1.5895761251449585,
      "learning_rate": 0.00015483458942204407,
      "loss": 3.0082,
      "step": 1680
    },
    {
      "epoch": 0.342,
      "grad_norm": 1.7449945211410522,
      "learning_rate": 0.0001531992899767329,
      "loss": 2.9772,
      "step": 1710
    },
    {
      "epoch": 0.348,
      "grad_norm": 1.7311995029449463,
      "learning_rate": 0.00015154390187241328,
      "loss": 3.0232,
      "step": 1740
    },
    {
      "epoch": 0.354,
      "grad_norm": 1.5771586894989014,
      "learning_rate": 0.00014986905020252482,
      "loss": 2.9551,
      "step": 1770
    },
    {
      "epoch": 0.36,
      "grad_norm": 2.324737548828125,
      "learning_rate": 0.00014817536741017152,
      "loss": 2.9891,
      "step": 1800
    },
    {
      "epoch": 0.366,
      "grad_norm": 1.8995561599731445,
      "learning_rate": 0.00014646349304930423,
      "loss": 2.935,
      "step": 1830
    },
    {
      "epoch": 0.372,
      "grad_norm": 1.871491551399231,
      "learning_rate": 0.00014473407354321762,
      "loss": 2.9297,
      "step": 1860
    },
    {
      "epoch": 0.378,
      "grad_norm": 2.2442541122436523,
      "learning_rate": 0.00014298776194045335,
      "loss": 2.931,
      "step": 1890
    },
    {
      "epoch": 0.384,
      "grad_norm": 1.7728983163833618,
      "learning_rate": 0.00014122521766820172,
      "loss": 2.9593,
      "step": 1920
    },
    {
      "epoch": 0.39,
      "grad_norm": 2.482252359390259,
      "learning_rate": 0.0001394471062832941,
      "loss": 2.9141,
      "step": 1950
    },
    {
      "epoch": 0.396,
      "grad_norm": 1.9230753183364868,
      "learning_rate": 0.00013765409922088137,
      "loss": 2.9421,
      "step": 1980
    },
    {
      "epoch": 0.4,
      "eval_loss": NaN,
      "eval_runtime": 407.7228,
      "eval_samples_per_second": 36.79,
      "eval_steps_per_second": 6.132,
      "step": 2000
    },
    {
      "epoch": 0.402,
      "grad_norm": 1.8165525197982788,
      "learning_rate": 0.0001358468735408922,
      "loss": 2.9889,
      "step": 2010
    },
    {
      "epoch": 0.408,
      "grad_norm": 1.946891188621521,
      "learning_rate": 0.00013402611167236746,
      "loss": 2.9547,
      "step": 2040
    },
    {
      "epoch": 0.414,
      "grad_norm": 1.930404543876648,
      "learning_rate": 0.00013219250115576744,
      "loss": 2.9665,
      "step": 2070
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.291346311569214,
      "learning_rate": 0.00013034673438334842,
      "loss": 2.9881,
      "step": 2100
    },
    {
      "epoch": 0.426,
      "grad_norm": 1.5351650714874268,
      "learning_rate": 0.00012848950833770764,
      "loss": 2.9234,
      "step": 2130
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.644801378250122,
      "learning_rate": 0.0001266215243285947,
      "loss": 2.9924,
      "step": 2160
    },
    {
      "epoch": 0.438,
      "grad_norm": 2.082756996154785,
      "learning_rate": 0.00012474348772808898,
      "loss": 2.9429,
      "step": 2190
    },
    {
      "epoch": 0.444,
      "grad_norm": 1.7061165571212769,
      "learning_rate": 0.0001228561077042431,
      "loss": 2.9426,
      "step": 2220
    },
    {
      "epoch": 0.45,
      "grad_norm": 2.3675363063812256,
      "learning_rate": 0.00012096009695329298,
      "loss": 2.9756,
      "step": 2250
    },
    {
      "epoch": 0.456,
      "grad_norm": 2.3314383029937744,
      "learning_rate": 0.00011905617143053549,
      "loss": 2.9391,
      "step": 2280
    },
    {
      "epoch": 0.462,
      "grad_norm": 1.7111704349517822,
      "learning_rate": 0.00011714505007997576,
      "loss": 2.9764,
      "step": 2310
    },
    {
      "epoch": 0.468,
      "grad_norm": 2.0413756370544434,
      "learning_rate": 0.00011522745456284556,
      "loss": 2.9356,
      "step": 2340
    },
    {
      "epoch": 0.474,
      "grad_norm": 1.9730101823806763,
      "learning_rate": 0.00011330410898509593,
      "loss": 2.9356,
      "step": 2370
    },
    {
      "epoch": 0.48,
      "grad_norm": 2.3011765480041504,
      "learning_rate": 0.0001113757396239663,
      "loss": 2.9201,
      "step": 2400
    },
    {
      "epoch": 0.486,
      "grad_norm": 2.10640549659729,
      "learning_rate": 0.00010944307465373404,
      "loss": 2.8706,
      "step": 2430
    },
    {
      "epoch": 0.492,
      "grad_norm": 1.9281591176986694,
      "learning_rate": 0.0001075068438707477,
      "loss": 2.8759,
      "step": 2460
    },
    {
      "epoch": 0.498,
      "grad_norm": 2.3105030059814453,
      "learning_rate": 0.00010556777841784724,
      "loss": 2.9986,
      "step": 2490
    },
    {
      "epoch": 0.5,
      "eval_loss": 2.951383113861084,
      "eval_runtime": 384.5016,
      "eval_samples_per_second": 39.012,
      "eval_steps_per_second": 6.502,
      "step": 2500
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.8760319948196411,
      "learning_rate": 0.00010362661050827642,
      "loss": 2.9386,
      "step": 2520
    },
    {
      "epoch": 0.51,
      "grad_norm": 2.4201927185058594,
      "learning_rate": 0.00010168407314919057,
      "loss": 3.003,
      "step": 2550
    },
    {
      "epoch": 0.516,
      "grad_norm": 2.6293461322784424,
      "learning_rate": 9.974089986486488e-05,
      "loss": 2.9489,
      "step": 2580
    },
    {
      "epoch": 0.522,
      "grad_norm": 1.9211394786834717,
      "learning_rate": 9.779782441970702e-05,
      "loss": 3.0233,
      "step": 2610
    },
    {
      "epoch": 0.528,
      "grad_norm": 2.174961805343628,
      "learning_rate": 9.58555805411797e-05,
      "loss": 2.9783,
      "step": 2640
    },
    {
      "epoch": 0.534,
      "grad_norm": 1.6866875886917114,
      "learning_rate": 9.391490164273634e-05,
      "loss": 2.9277,
      "step": 2670
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.3154709339141846,
      "learning_rate": 9.197652054687618e-05,
      "loss": 2.9812,
      "step": 2700
    },
    {
      "epoch": 0.546,
      "grad_norm": 2.0523855686187744,
      "learning_rate": 9.004116920842188e-05,
      "loss": 2.9143,
      "step": 2730
    },
    {
      "epoch": 0.552,
      "grad_norm": 1.5794726610183716,
      "learning_rate": 8.810957843812519e-05,
      "loss": 2.9313,
      "step": 2760
    },
    {
      "epoch": 0.558,
      "grad_norm": 2.2991602420806885,
      "learning_rate": 8.618247762670445e-05,
      "loss": 2.874,
      "step": 2790
    },
    {
      "epoch": 0.564,
      "grad_norm": 2.207789897918701,
      "learning_rate": 8.426059446941816e-05,
      "loss": 2.9328,
      "step": 2820
    },
    {
      "epoch": 0.57,
      "grad_norm": 2.3327033519744873,
      "learning_rate": 8.234465469127919e-05,
      "loss": 2.9238,
      "step": 2850
    },
    {
      "epoch": 0.576,
      "grad_norm": 2.0694377422332764,
      "learning_rate": 8.043538177301255e-05,
      "loss": 2.9247,
      "step": 2880
    },
    {
      "epoch": 0.582,
      "grad_norm": 1.8859715461730957,
      "learning_rate": 7.853349667786091e-05,
      "loss": 2.8845,
      "step": 2910
    },
    {
      "epoch": 0.588,
      "grad_norm": 2.1176528930664062,
      "learning_rate": 7.663971757934063e-05,
      "loss": 2.9873,
      "step": 2940
    },
    {
      "epoch": 0.594,
      "grad_norm": 1.4501121044158936,
      "learning_rate": 7.475475959005123e-05,
      "loss": 2.9054,
      "step": 2970
    },
    {
      "epoch": 0.6,
      "grad_norm": 2.4106671810150146,
      "learning_rate": 7.287933449164069e-05,
      "loss": 2.988,
      "step": 3000
    },
    {
      "epoch": 0.6,
      "eval_loss": 2.937079668045044,
      "eval_runtime": 400.1842,
      "eval_samples_per_second": 37.483,
      "eval_steps_per_second": 6.247,
      "step": 3000
    },
    {
      "epoch": 0.606,
      "grad_norm": 2.316727638244629,
      "learning_rate": 7.10141504660286e-05,
      "loss": 2.921,
      "step": 3030
    },
    {
      "epoch": 0.612,
      "grad_norm": 1.7864233255386353,
      "learning_rate": 6.915991182798865e-05,
      "loss": 2.949,
      "step": 3060
    },
    {
      "epoch": 0.618,
      "grad_norm": 2.2575597763061523,
      "learning_rate": 6.731731875919122e-05,
      "loss": 2.9561,
      "step": 3090
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.7161673307418823,
      "learning_rate": 6.54870670438069e-05,
      "loss": 2.9447,
      "step": 3120
    },
    {
      "epoch": 0.63,
      "grad_norm": 2.379004955291748,
      "learning_rate": 6.366984780577029e-05,
      "loss": 2.9932,
      "step": 3150
    },
    {
      "epoch": 0.636,
      "grad_norm": 1.9240244626998901,
      "learning_rate": 6.186634724780394e-05,
      "loss": 2.9672,
      "step": 3180
    },
    {
      "epoch": 0.642,
      "grad_norm": 1.7759380340576172,
      "learning_rate": 6.0077246392300105e-05,
      "loss": 2.9106,
      "step": 3210
    },
    {
      "epoch": 0.648,
      "grad_norm": 2.354707956314087,
      "learning_rate": 5.8303220824159225e-05,
      "loss": 2.9258,
      "step": 3240
    },
    {
      "epoch": 0.654,
      "grad_norm": 1.9108917713165283,
      "learning_rate": 5.6544940435681084e-05,
      "loss": 2.9229,
      "step": 3270
    },
    {
      "epoch": 0.66,
      "grad_norm": 2.6444122791290283,
      "learning_rate": 5.4803069173605914e-05,
      "loss": 2.9542,
      "step": 3300
    },
    {
      "epoch": 0.666,
      "grad_norm": 1.8686453104019165,
      "learning_rate": 5.307826478840068e-05,
      "loss": 2.9488,
      "step": 3330
    },
    {
      "epoch": 0.672,
      "grad_norm": 2.1775670051574707,
      "learning_rate": 5.1371178585884714e-05,
      "loss": 2.8919,
      "step": 3360
    },
    {
      "epoch": 0.678,
      "grad_norm": 2.19564151763916,
      "learning_rate": 4.96824551812895e-05,
      "loss": 2.8902,
      "step": 3390
    },
    {
      "epoch": 0.684,
      "grad_norm": 1.7358858585357666,
      "learning_rate": 4.801273225584445e-05,
      "loss": 2.8443,
      "step": 3420
    },
    {
      "epoch": 0.69,
      "grad_norm": 2.458846092224121,
      "learning_rate": 4.63626403159811e-05,
      "loss": 2.9189,
      "step": 3450
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.8592674732208252,
      "learning_rate": 4.4732802455246957e-05,
      "loss": 2.9117,
      "step": 3480
    },
    {
      "epoch": 0.7,
      "eval_loss": 2.923126220703125,
      "eval_runtime": 397.3866,
      "eval_samples_per_second": 37.747,
      "eval_steps_per_second": 6.291,
      "step": 3500
    },
    {
      "epoch": 0.702,
      "grad_norm": 1.7215977907180786,
      "learning_rate": 4.3123834119017956e-05,
      "loss": 2.9519,
      "step": 3510
    },
    {
      "epoch": 0.708,
      "grad_norm": 2.1721396446228027,
      "learning_rate": 4.1536342872099545e-05,
      "loss": 2.8744,
      "step": 3540
    },
    {
      "epoch": 0.714,
      "grad_norm": 1.5368711948394775,
      "learning_rate": 3.9970928169303126e-05,
      "loss": 2.8673,
      "step": 3570
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.9594473838806152,
      "learning_rate": 3.8428181129084996e-05,
      "loss": 3.0024,
      "step": 3600
    },
    {
      "epoch": 0.726,
      "grad_norm": 1.7988468408584595,
      "learning_rate": 3.6908684310333516e-05,
      "loss": 2.9728,
      "step": 3630
    },
    {
      "epoch": 0.732,
      "grad_norm": 2.166785717010498,
      "learning_rate": 3.541301149238798e-05,
      "loss": 2.977,
      "step": 3660
    },
    {
      "epoch": 0.738,
      "grad_norm": 2.362128973007202,
      "learning_rate": 3.3941727458373175e-05,
      "loss": 2.9183,
      "step": 3690
    },
    {
      "epoch": 0.744,
      "grad_norm": 1.5668965578079224,
      "learning_rate": 3.249538778193074e-05,
      "loss": 2.9474,
      "step": 3720
    },
    {
      "epoch": 0.75,
      "grad_norm": 2.5934884548187256,
      "learning_rate": 3.107453861742815e-05,
      "loss": 2.9846,
      "step": 3750
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.9662647247314453,
      "learning_rate": 2.9679716493724795e-05,
      "loss": 2.8965,
      "step": 3780
    },
    {
      "epoch": 0.762,
      "grad_norm": 1.7202529907226562,
      "learning_rate": 2.8311448111572304e-05,
      "loss": 2.9059,
      "step": 3810
    },
    {
      "epoch": 0.768,
      "grad_norm": 2.2851788997650146,
      "learning_rate": 2.697025014472656e-05,
      "loss": 2.9298,
      "step": 3840
    },
    {
      "epoch": 0.774,
      "grad_norm": 2.0785388946533203,
      "learning_rate": 2.5656629044845716e-05,
      "loss": 2.8884,
      "step": 3870
    },
    {
      "epoch": 0.78,
      "grad_norm": 2.213972568511963,
      "learning_rate": 2.4371080850248118e-05,
      "loss": 2.9263,
      "step": 3900
    },
    {
      "epoch": 0.786,
      "grad_norm": 1.643247365951538,
      "learning_rate": 2.3114090998602865e-05,
      "loss": 2.9242,
      "step": 3930
    },
    {
      "epoch": 0.792,
      "grad_norm": 1.3878822326660156,
      "learning_rate": 2.1886134143622727e-05,
      "loss": 2.9292,
      "step": 3960
    },
    {
      "epoch": 0.798,
      "grad_norm": 1.8136076927185059,
      "learning_rate": 2.0687673975829668e-05,
      "loss": 3.0077,
      "step": 3990
    },
    {
      "epoch": 0.8,
      "eval_loss": 2.9177920818328857,
      "eval_runtime": 386.6963,
      "eval_samples_per_second": 38.79,
      "eval_steps_per_second": 6.465,
      "step": 4000
    },
    {
      "epoch": 0.804,
      "grad_norm": 2.0472044944763184,
      "learning_rate": 1.9519163047459978e-05,
      "loss": 2.8928,
      "step": 4020
    },
    {
      "epoch": 0.81,
      "grad_norm": 2.3202829360961914,
      "learning_rate": 1.8381042601575248e-05,
      "loss": 2.9406,
      "step": 4050
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.982318639755249,
      "learning_rate": 1.7273742405444214e-05,
      "loss": 2.9302,
      "step": 4080
    },
    {
      "epoch": 0.822,
      "grad_norm": 2.1002750396728516,
      "learning_rate": 1.6197680588257437e-05,
      "loss": 2.9097,
      "step": 4110
    },
    {
      "epoch": 0.828,
      "grad_norm": 1.8211560249328613,
      "learning_rate": 1.51532634832372e-05,
      "loss": 3.022,
      "step": 4140
    },
    {
      "epoch": 0.834,
      "grad_norm": 1.604237675666809,
      "learning_rate": 1.4140885474201315e-05,
      "loss": 2.8543,
      "step": 4170
    },
    {
      "epoch": 0.84,
      "grad_norm": 2.717036724090576,
      "learning_rate": 1.3160928846639275e-05,
      "loss": 2.9504,
      "step": 4200
    },
    {
      "epoch": 0.846,
      "grad_norm": 1.9626630544662476,
      "learning_rate": 1.2213763643357001e-05,
      "loss": 2.84,
      "step": 4230
    },
    {
      "epoch": 0.852,
      "grad_norm": 1.8098981380462646,
      "learning_rate": 1.1299747524744309e-05,
      "loss": 2.9369,
      "step": 4260
    },
    {
      "epoch": 0.858,
      "grad_norm": 2.0699923038482666,
      "learning_rate": 1.0419225633718421e-05,
      "loss": 2.8836,
      "step": 4290
    },
    {
      "epoch": 0.864,
      "grad_norm": 1.9685330390930176,
      "learning_rate": 9.572530465393958e-06,
      "loss": 2.9404,
      "step": 4320
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.7457387447357178,
      "learning_rate": 8.759981741529e-06,
      "loss": 2.9442,
      "step": 4350
    },
    {
      "epoch": 0.876,
      "grad_norm": 2.068697929382324,
      "learning_rate": 7.981886289794516e-06,
      "loss": 2.9415,
      "step": 4380
    },
    {
      "epoch": 0.882,
      "grad_norm": 1.7559130191802979,
      "learning_rate": 7.238537927912748e-06,
      "loss": 2.9374,
      "step": 4410
    },
    {
      "epoch": 0.888,
      "grad_norm": 2.095444917678833,
      "learning_rate": 6.530217352708301e-06,
      "loss": 2.9246,
      "step": 4440
    },
    {
      "epoch": 0.894,
      "grad_norm": 1.793681025505066,
      "learning_rate": 5.857192034113757e-06,
      "loss": 2.8837,
      "step": 4470
    },
    {
      "epoch": 0.9,
      "grad_norm": 2.569657564163208,
      "learning_rate": 5.219716114170026e-06,
      "loss": 2.9167,
      "step": 4500
    },
    {
      "epoch": 0.9,
      "eval_loss": 2.914804220199585,
      "eval_runtime": 388.6935,
      "eval_samples_per_second": 38.591,
      "eval_steps_per_second": 6.432,
      "step": 4500
    },
    {
      "epoch": 0.906,
      "grad_norm": 2.014864206314087,
      "learning_rate": 4.618030311059352e-06,
      "loss": 2.8754,
      "step": 4530
    },
    {
      "epoch": 0.912,
      "grad_norm": 2.280636787414551,
      "learning_rate": 4.052361828207496e-06,
      "loss": 2.9138,
      "step": 4560
    },
    {
      "epoch": 0.918,
      "grad_norm": 2.0253641605377197,
      "learning_rate": 3.522924268489003e-06,
      "loss": 2.9107,
      "step": 4590
    },
    {
      "epoch": 0.924,
      "grad_norm": 2.1296188831329346,
      "learning_rate": 3.0299175535684066e-06,
      "loss": 2.9167,
      "step": 4620
    },
    {
      "epoch": 0.93,
      "grad_norm": 2.404764413833618,
      "learning_rate": 2.5735278484074866e-06,
      "loss": 2.8898,
      "step": 4650
    },
    {
      "epoch": 0.936,
      "grad_norm": 2.468865394592285,
      "learning_rate": 2.1539274909672335e-06,
      "loss": 2.9145,
      "step": 4680
    },
    {
      "epoch": 0.942,
      "grad_norm": 1.8472211360931396,
      "learning_rate": 1.771274927131139e-06,
      "loss": 2.9194,
      "step": 4710
    },
    {
      "epoch": 0.948,
      "grad_norm": 2.018775701522827,
      "learning_rate": 1.4257146508741437e-06,
      "loss": 2.9979,
      "step": 4740
    },
    {
      "epoch": 0.954,
      "grad_norm": 1.9137471914291382,
      "learning_rate": 1.1173771497001273e-06,
      "loss": 2.9178,
      "step": 4770
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.247105121612549,
      "learning_rate": 8.463788553683016e-07,
      "loss": 2.9004,
      "step": 4800
    },
    {
      "epoch": 0.966,
      "grad_norm": 1.724480152130127,
      "learning_rate": 6.128220999272349e-07,
      "loss": 2.9502,
      "step": 4830
    },
    {
      "epoch": 0.972,
      "grad_norm": 1.9140628576278687,
      "learning_rate": 4.1679507707315104e-07,
      "loss": 2.9442,
      "step": 4860
    },
    {
      "epoch": 0.978,
      "grad_norm": 2.4066011905670166,
      "learning_rate": 2.583718088469689e-07,
      "loss": 2.9808,
      "step": 4890
    },
    {
      "epoch": 0.984,
      "grad_norm": 1.9375624656677246,
      "learning_rate": 1.376121176826728e-07,
      "loss": 2.9047,
      "step": 4920
    },
    {
      "epoch": 0.99,
      "grad_norm": 2.6050798892974854,
      "learning_rate": 5.456160381779318e-08,
      "loss": 2.9501,
      "step": 4950
    },
    {
      "epoch": 0.996,
      "grad_norm": 2.817955255508423,
      "learning_rate": 9.251628074136155e-09,
      "loss": 2.9168,
      "step": 4980
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.911470890045166,
      "eval_runtime": 386.2309,
      "eval_samples_per_second": 38.837,
      "eval_steps_per_second": 6.473,
      "step": 5000
    },
    {
      "epoch": 1.004,
      "grad_norm": 1.6889559030532837,
      "learning_rate": 6.596460922943499e-05,
      "loss": 3.0301,
      "step": 5010
    },
    {
      "epoch": 1.016,
      "grad_norm": 1.5140411853790283,
      "learning_rate": 6.481328246622369e-05,
      "loss": 2.8896,
      "step": 5040
    },
    {
      "epoch": 1.028,
      "grad_norm": 1.4340006113052368,
      "learning_rate": 6.366725469324605e-05,
      "loss": 2.88,
      "step": 5070
    },
    {
      "epoch": 1.04,
      "grad_norm": 1.6555525064468384,
      "learning_rate": 6.25266984980693e-05,
      "loss": 2.8943,
      "step": 5100
    },
    {
      "epoch": 1.052,
      "grad_norm": 1.334859013557434,
      "learning_rate": 6.139178564426107e-05,
      "loss": 2.8763,
      "step": 5130
    },
    {
      "epoch": 1.064,
      "grad_norm": 1.4208797216415405,
      "learning_rate": 6.026268704552265e-05,
      "loss": 2.8732,
      "step": 5160
    },
    {
      "epoch": 1.076,
      "grad_norm": 1.4278489351272583,
      "learning_rate": 5.913957273994983e-05,
      "loss": 2.9547,
      "step": 5190
    },
    {
      "epoch": 1.088,
      "grad_norm": 1.2569156885147095,
      "learning_rate": 5.802261186442595e-05,
      "loss": 2.8511,
      "step": 5220
    },
    {
      "epoch": 1.1,
      "grad_norm": 1.7675855159759521,
      "learning_rate": 5.691197262915029e-05,
      "loss": 2.8057,
      "step": 5250
    },
    {
      "epoch": 1.112,
      "grad_norm": 1.4456216096878052,
      "learning_rate": 5.580782229230648e-05,
      "loss": 2.8982,
      "step": 5280
    },
    {
      "epoch": 1.124,
      "grad_norm": 1.2876956462860107,
      "learning_rate": 5.4710327134873826e-05,
      "loss": 2.8502,
      "step": 5310
    },
    {
      "epoch": 1.136,
      "grad_norm": 1.6604055166244507,
      "learning_rate": 5.3619652435586164e-05,
      "loss": 2.8905,
      "step": 5340
    },
    {
      "epoch": 1.148,
      "grad_norm": 1.425156593322754,
      "learning_rate": 5.253596244604137e-05,
      "loss": 2.8297,
      "step": 5370
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.5544896125793457,
      "learning_rate": 5.145942036596576e-05,
      "loss": 2.8682,
      "step": 5400
    },
    {
      "epoch": 1.172,
      "grad_norm": 1.3480675220489502,
      "learning_rate": 5.039018831863671e-05,
      "loss": 2.8389,
      "step": 5430
    },
    {
      "epoch": 1.184,
      "grad_norm": 1.2011767625808716,
      "learning_rate": 4.932842732646769e-05,
      "loss": 2.8438,
      "step": 5460
    },
    {
      "epoch": 1.196,
      "grad_norm": 1.568190097808838,
      "learning_rate": 4.82742972867586e-05,
      "loss": 2.8727,
      "step": 5490
    },
    {
      "epoch": 1.2,
      "eval_loss": 2.8659167289733887,
      "eval_runtime": 465.2679,
      "eval_samples_per_second": 32.239,
      "eval_steps_per_second": 5.373,
      "step": 5500
    },
    {
      "epoch": 1.208,
      "grad_norm": 1.4031261205673218,
      "learning_rate": 4.3824145926169036e-05,
      "loss": 2.8706,
      "step": 5520
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.6436315774917603,
      "learning_rate": 4.2853425474604846e-05,
      "loss": 2.8657,
      "step": 5550
    },
    {
      "epoch": 1.232,
      "grad_norm": 1.4327278137207031,
      "learning_rate": 4.189063637935487e-05,
      "loss": 2.8192,
      "step": 5580
    },
    {
      "epoch": 1.2439999999999998,
      "grad_norm": 1.2040610313415527,
      "learning_rate": 4.0935912265635124e-05,
      "loss": 2.8472,
      "step": 5610
    },
    {
      "epoch": 1.2560000000000002,
      "grad_norm": 1.5686460733413696,
      "learning_rate": 3.99893856393253e-05,
      "loss": 2.8539,
      "step": 5640
    },
    {
      "epoch": 1.268,
      "grad_norm": 1.3489015102386475,
      "learning_rate": 3.905118786857824e-05,
      "loss": 2.8273,
      "step": 5670
    },
    {
      "epoch": 1.2800000000000002,
      "grad_norm": 1.7985553741455078,
      "learning_rate": 3.8121449165587255e-05,
      "loss": 2.8758,
      "step": 5700
    },
    {
      "epoch": 1.292,
      "grad_norm": 1.5885764360427856,
      "learning_rate": 3.7200298568514214e-05,
      "loss": 2.7782,
      "step": 5730
    },
    {
      "epoch": 1.304,
      "grad_norm": 1.3992838859558105,
      "learning_rate": 3.628786392358028e-05,
      "loss": 2.8083,
      "step": 5760
    },
    {
      "epoch": 1.316,
      "grad_norm": 1.5521669387817383,
      "learning_rate": 3.538427186732216e-05,
      "loss": 2.8345,
      "step": 5790
    },
    {
      "epoch": 1.328,
      "grad_norm": 1.5335328578948975,
      "learning_rate": 3.448964780901622e-05,
      "loss": 2.8119,
      "step": 5820
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.6657297611236572,
      "learning_rate": 3.3604115913273146e-05,
      "loss": 2.8852,
      "step": 5850
    },
    {
      "epoch": 1.352,
      "grad_norm": 1.2951228618621826,
      "learning_rate": 3.272779908280493e-05,
      "loss": 2.8556,
      "step": 5880
    },
    {
      "epoch": 1.364,
      "grad_norm": 1.4396499395370483,
      "learning_rate": 3.1860818941367367e-05,
      "loss": 2.8573,
      "step": 5910
    },
    {
      "epoch": 1.376,
      "grad_norm": 1.4789533615112305,
      "learning_rate": 3.1003295816879985e-05,
      "loss": 2.8821,
      "step": 5940
    },
    {
      "epoch": 1.388,
      "grad_norm": 1.4734429121017456,
      "learning_rate": 3.0155348724725673e-05,
      "loss": 2.8728,
      "step": 5970
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.7435897588729858,
      "learning_rate": 2.9317095351232648e-05,
      "loss": 2.7735,
      "step": 6000
    },
    {
      "epoch": 1.4,
      "eval_loss": 2.859515428543091,
      "eval_runtime": 469.3571,
      "eval_samples_per_second": 31.959,
      "eval_steps_per_second": 5.326,
      "step": 6000
    }
  ],
  "logging_steps": 30,
  "max_steps": 6000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.4563764268544e+16,
  "train_batch_size": 6,
  "trial_name": null,
  "trial_params": null
}